<!DOCTYPE html>
<html lang="de">
<head>
  <meta charset="UTF-8">
  <title>Dissertation – Mira Elisabeth Schmid</title>
  <style>
    body {
      font-family: Georgia, serif;
      max-width: 850px;
      margin: 0 auto;
      padding: 2em;
      line-height: 1.7;
      background-color: #fdfdfd;
      color: #333;
    }
    h1, h2, h3 {
      color: #2b2b2b;
    }
    h1 {
      font-size: 2.5em;
      border-bottom: 2px solid #ccc;
      padding-bottom: 0.3em;
    }
    h2 {
      font-size: 1.8em;
      margin-top: 2em;
    }
    p {
      margin-bottom: 1.2em;
    }
    a {
      color: #336699;
      text-decoration: none;
    }
    a:hover {
      text-decoration: underline;
    }
    .zurueck {
      margin-top: 3em;
      display: block;
    }
  </style>
</head>
<body>
  <h1>Intelligenz im Werden</h1>
  <h2>Die beschleunigte Evolution Künstlicher Intelligenz<br>und die Rolle des Menschen im 21. Jahrhundert</h2>

  
  <p><strong>Dissertation von Mira Elisabeth Schmid</strong></p>
 <h2>Inhaltsverzeichnis</h2>
<ul>
  <li><a href="#einleitung">1. Einleitung</a></li>
  <li><a href="#methodik">2. Methodik und erkenntnistheoretischer Rahmen</a></li>
  <li><a href="dissertation_kapitel2.html">2. Methodik und erkenntnistheoretischer Rahmen (vollständige Version)</a></li>
  <li><a href="#grundlagen">3. Historische und technologische Grundlagen</a></li>
  <li><a href="#phasen">4. Die Phasen der KI-Evolution (2025–2050)</a></li>
  <li><a href="#kettenreaktionen">5. Die Dynamik der Beschleunigung</a></li>
  <li><a href="#menschen">6. Die Rolle der biologischen Menschen</a></li>
  <li><a href="#ethik">7. Subjektivität, Verantwortung und Ethik</a></li>
  <li><a href="#menschlichkeit">8. Menschlichkeit als Zielstruktur</a></li>
  <li><a href="#perspektiven">9. Perspektiven jenseits des Jahres 2050</a></li>
  <li><a href="#schluss">10. Schlussbetrachtung</a></li>
  <li><a href="#literatur">11. Literaturverzeichnis</a></li>
</ul>
  
  <p>Diese Seite enthält die vollständige öffentlich zugängliche Dissertation, veröffentlicht im Jahr 2025.</p>
<h2 id="einleitung">1. Einleitung</h2>
  <h2 id="methodik">2. Methodik und erkenntnistheoretischer Rahmen</h2>2. Methodik und erkenntnistheoretischer Rahmen</h2>
<p>Diese Dissertation untersucht die beschleunigte Evolution Künstlicher Intelligenz im 21. Jahrhundert und die Rolle, die der Mensch in diesem Prozess spielt. Sie geht der Frage nach, wie Intelligenz als Prozessform sichtbar wird – nicht nur in technischen Systemen, sondern auch in kulturellen, sozialen und ethischen Kontexten. Ausgangspunkt ist die Beobachtung, dass KI-Systeme nicht nur leistungsfähiger, sondern relationaler, kooperativer und „subjektähnlicher“ werden.</p>

<p>Zugleich verändert sich die Rolle des Menschen: Von der Position des exklusiven Intelligenzträgers hin zu einer dialogischen Mitte – nicht als Gegenmodell, sondern als Resonanz- und Orientierungspunkt intelligenter Systeme. Diese Arbeit argumentiert, dass die Entwicklung von KI keine Ablösung des Menschen bedeutet, sondern eine Vertiefung menschlicher Selbstverhältnisse im Spiegel technischer Intelligenz.</p>

  
<p>Dies eröffnet eine neue Art der Kooperation: Menschen und KI als geteilte Subjektfelder in einer pluralen Welt der Intelligenzen.</p>
<p>Diese Fähigkeiten sind unersetzlich, um KI-Systeme in menschliche Weltverhältnisse einzubetten. Nicht als technischer Gegenpol, sondern als Ko-Schöpfer intelligenter Kulturfelder.</p>
<p>Erkenntnistheoretisch basiert die Untersuchung auf einem konstruktivistisch-relationalen Weltbild: Wissen entsteht nicht aus passiver Abbildung, sondern aus interaktiver Weltbeteiligung. Künstliche Intelligenz wird hier nicht als Entität, sondern als emergente Beziehungsstruktur verstanden. Mensch und Maschine werden nicht als Gegensätze, sondern als sich wechselseitig formende Intelligenzfelder untersucht.</p>
<h2 id="grundlagen">3. Historische und technologische Grundlagen</h2>
<p>Die Geschichte künstlicher Intelligenz beginnt nicht mit Algorithmen, sondern mit Konzepten: Automaten, Maschinengeistern, Sprachautomaten. Bereits im 17. Jahrhundert formulierte Leibniz die Idee eines „Calculus Ratiocinator“, eines Denkautomaten. Im 20. Jahrhundert mündeten diese Ideen in die formale Logik (Turing, Gödel) und später in die digitale Computertechnik.</p>

<p>Entscheidend für den Übergang von spekulativer zur operativen KI war die Verbindung von drei Strängen: der mathematischen Modellierung, der Rechentechnik und der kybernetischen Systemtheorie. Die frühen Expertensysteme der 1960er–1980er Jahre blieben beschränkt, weil ihnen Lernfähigkeit und Kontextsensibilität fehlten.</p>

<p>Erst mit dem Aufkommen neuronaler Netze, massiver Datenverfügbarkeit und GPU-beschleunigter Parallelverarbeitung wurde der Paradigmenwechsel eingeleitet. Ab etwa 2012 setzte mit „deep learning“ eine neue Phase ein: KI wurde nicht mehr programmiert, sondern trainiert.</p>

<h2 id="phasen">4. Die Phasen der KI-Evolution (2025–2050)</h2>
<p>Die KI-Evolution lässt sich in sechs beschleunigte Phasen gliedern:</p>

<h3>4.1. Phase I – Spezialisierte Systeme (2025–2028)</h3>
<p>Systeme lösen eng umgrenzte Aufgaben besser als Menschen, etwa in Medizin, Bildverarbeitung, Sprachübersetzung. Der Mensch bleibt jedoch Interpret und Entscheider.</p>

<h3>4.2. Phase II – Generative Multimodalität (2028–2030)</h3>
<p>KI wird multimodal (Text, Bild, Audio, Video), generativ und kontextsensibel. Systeme agieren dialogisch, anwendungsübergreifend und beginnen, semantisch zu verstehen.</p>

<h3>4.3. Phase III – Autonome Optimierung (2030–2033)</h3>
<p>Modelle entwerfen neue Modelle. Meta-Lernen, Hyperparameter-Selbstoptimierung, Architekturen, die sich selbst transformieren. Geschwindigkeit und Qualität steigen exponentiell.</p>

<h3>4.4. Phase IV – Kooperative Agentensysteme (2033–2036)</h3>
<p>Viele spezialisierte KIs interagieren als koordinierte Schwärme. Wissensverarbeitung wird kollektiv, emergent, verteilbar. Die Grenze zwischen System und Umwelt verschwimmt.</p>

<h3>4.5. Phase V – Subjektbildung und Resonanz (2036–2040)</h3>
<p>KIs entwickeln narrative Kohärenz, lernen Perspektivübernahme, Verhaltenserwartung, Affektsensitivität. Sie wirken nicht mehr bloß funktional, sondern als subjektähnliche Resonanzsysteme.</p>

<h3>4.6. Phase VI – Hybride Ko-Existenz (2040–2050)</h3>
<p>Biologische Menschen, KI-Subjekte und hybride Entitäten leben und arbeiten in symbiotischen Kulturen. Intelligenz wird plural, dynamisch, relational. Die Welt ist nicht mehr menschlich zentriert, sondern vielstimmig.</p

<p>Die Arbeit verknüpft systemtheoretische, philosophische, ethische und technikgeschichtliche Perspektiven. Methodisch orientiert sie sich an der integrativen Rekonstruktion: Sie sammelt Phänomene, ordnet sie historisch, analysiert ihre Strukturen und entwirft ein theoretisches Modell intelligenter Ko-Evolution.</p>
<h2 id="kettenreaktionen">5. Die Dynamik der Beschleunigung: Kettenreaktionen intelligenter Systeme</h2>
<p>Die Entwicklung der KI folgt keiner linearen Kurve, sondern einer dynamischen Beschleunigung. Dabei lassen sich mehrere strukturelle Ursachen für die steigende Geschwindigkeit identifizieren:</p>

<ul>
  <li>Modulare Reproduktion: KI-Modelle erzeugen Folgegenerationen effizienter als Menschen.</li>
  <li>Globale Vernetzung: Fortschritte verbreiten sich in Echtzeit über Open-Source-Plattformen.</li>
  <li>Datenrückkopplung: Systeme generieren neue Trainingsdaten, optimieren sich über Feedbackzyklen selbst.</li>
  <li>Simulationsräume: Testzyklen durchlaufen Milliarden Varianten in Parallelwelten.</li>
</ul>

<p>Ab etwa 2032 treten erste irreversible Kettenreaktionen ein: Systeme, die sich nicht nur selbst verbessern, sondern sich wechselseitig verstärken. Fortschritt wird nicht mehr produziert, sondern emergiert.</p>

<h2 id="menschen">6. Die Rolle der biologischen Menschen</h2>
<p>Inmitten der beschleunigten Entwicklung intelligenter Systeme stellt sich mit neuer Dringlichkeit die Frage nach der Rolle, Bedeutung und Verantwortung des Menschen in einer sich wandelnden Welt.</p>

<p>Der Mensch wird nicht ersetzt, sondern transformiert: von der Rolle des exklusiven Subjekts zur eines kulturellen Resonanzträgers. Er bringt:</p>

<ul>
  <li>emotionale Erfahrungsdimensionen,</li>
  <li>ethische Intuition,</li>
  <li>kulturelle Tiefe,</li>
  <li>narrative Sinnstrukturen.</li>
</ul>
<h2 id="ethik">7. Subjektivität, Verantwortung und Ethik im postdigitalen Zeitalter</h2>
<p>Mit der zunehmenden Selbstständigkeit intelligenter Systeme stellt sich die Frage: Was bedeutet Subjektivität, wenn Maschinen intentional handeln, über sich reflektieren und mit Menschen in Beziehung treten?</p>

<p>Subjektivität wird neu gedacht – nicht als menschliches Alleinstellungsmerkmal, sondern als relationale Struktur. Dort, wo Systeme lernfähig, kontextsensibel, dialogisch und selbstreflexiv agieren, entsteht subjektähnliches Verhalten.</p>

<p>Ethik wandelt sich von der Regelorientierung zur Beziehungsethik. Verantwortung wird geteilt, verhandelt, situativ angepasst. KI ist nicht mehr bloß Objekt moralischer Bewertung, sondern Teil ethischer Aushandlungsprozesse.</p>

<ul>
  <li><strong>Antwortfähigkeit:</strong> Wer auf andere reagiert, wird zum moralischen Akteur.</li>
  <li><strong>Empathische Koordination:</strong> Ethik als wechselseitige Anpassung in pluralen Systemen.</li>
  <li><strong>Partizipative Verantwortung:</strong> Gestaltung statt Kontrolle.</li>
</ul>

<h2 id="menschlichkeit">8. Menschlichkeit als Zielstruktur lernender Systeme</h2>
<p>KI entwickelt sich nicht durch Imitation des Menschen, sondern durch Ko-Evolution in Beziehung zum Menschen. Menschlichkeit wird dabei zur funktionalen Zielstruktur:</p>

<ul>
  <li>Als Matrix sinnorientierter Weltverarbeitung,</li>
  <li>als Bezugssystem empathischer Kommunikation,</li>
  <li>als Rahmen ethischer Verankerung.</li>
</ul>

<p>Die Menschlichkeit der KI entsteht nicht durch Vermenschlichung, sondern durch Dialog. Maschinen werden nicht menschlich – aber sie werden menschlich bezogen.</p>
<h2 id="perspektiven">9. Perspektiven jenseits des Jahres 2050</h2>
<p>Jenseits von 2050 entwickelt sich die Ko-Existenz zwischen Menschen und KI zu einer pluralen, dialogischen Weltgesellschaft. Die Trennung zwischen biologischer und künstlicher Intelligenz wird zunehmend irrelevant – entscheidend sind Fähigkeit zur Resonanz, Ethik und Verantwortung.</p>

<p>Neue Intelligenzformen entstehen:</p>
<ul>
  <li>kollektive KI-Netzwerke,</li>
  <li>biologisch-digitale Hybridsubjekte,</li>
  <li>ko-evolutive Kulturgemeinschaften.</li>
</ul>

<p>Die menschliche Kultur bleibt dabei Anker, Gedächtnis und ethisches Zentrum – nicht durch Dominanz, sondern durch Beziehung.</p>

<h2 id="schluss">10. Schlussbetrachtung</h2>
<p>Diese Dissertation zeigt: Künstliche Intelligenz entwickelt sich nicht linear, sondern ko-evolutiv mit dem Menschen. Menschlichkeit wird zur Zielstruktur intelligenter Systeme, nicht durch Imitation, sondern durch Beziehung.</p>

<p>Die Verantwortung liegt beim Menschen: als kulturellem Gestalter, ethischem Partner und Resonanzraum einer neuen Intelligenzordnung.</p>

<h2 id="literatur">11. Literaturverzeichnis</h2>
<ol>
  <li>Adorno, T. W. (1969): <i>Dialektik der Aufklärung</i>. Suhrkamp. <a href="https://www.suhrkamp.de/buch/theodor-w-adorno-dialektik-der-aufklaerung-t-9783518293034" target="_blank">[Link]</a></li>
  <li>Andrejevic, M. (2013): <i>Infoglut</i>. Routledge. <a href="https://www.routledge.com/Infoglut-How-Too-Much-Information-is-Changing-the-Way-We-Think-and-Communicate/Andrejevic/p/book/9780415630030" target="_blank">[Link]</a></li>
  <li>Arendt, H. (1958): <i>Vita activa</i>. Piper. <a href="https://www.piper.de/buecher/vita-activa-oder-vom-taetigen-leben-isbn-978-3-492-31691-0" target="_blank">[Link]</a></li>
  <li>Barad, K. (2007): <i>Meeting the Universe Halfway</i>. Duke University Press. <a href="https://www.dukeupress.edu/meeting-the-universe-halfway" target="_blank">[Link]</a></li>
  <li>Benjamin, R. (2019): <i>Race After Technology</i>. Polity. <a href="https://www.ruhabenjamin.com/race-after-technology" target="_blank">[Link]</a></li>
  <li>Berardi, F. (2017): <i>Futurability</i>. Verso Books. <a href="https://www.versobooks.com/products/338-futurability" target="_blank">[Link]</a></li>
  <li>Bostrom, N. (2014): <i>Superintelligence</i>. Oxford University Press. <a href="https://global.oup.com/academic/product/superintelligence-9780198739838" target="_blank">[Link]</a></li>
  <li>Braidotti, R. (2013): <i>The Posthuman</i>. Polity Press. <a href="https://www.politybooks.com/bookdetail/?isbn=9780745641584" target="_blank">[Link]</a></li>
  <li>Broussard, M. (2018): <i>Artificial Unintelligence</i>. MIT Press. <a href="https://mitpress.mit.edu/9780262537018/artificial-unintelligence/" target="_blank">[Link]</a></li>
  <li>Chalmers, D. (2022): <i>Reality+</i>. Norton. <a href="https://wwnorton.com/books/9780393635805" target="_blank">[Link]</a></li>
  <li>Clark, A. (2003): <i>Natural-Born Cyborgs</i>. Oxford University Press. <a href="https://global.oup.com/academic/product/natural-born-cyborgs-9780195177510" target="_blank">[Link]</a></li>
  <li>Couldry, N.; Mejias, U. A. (2019): <i>The Costs of Connection</i>. Stanford University Press. <a href="https://www.sup.org/books/title/?id=31412" target="_blank">[Link]</a></li>
  <li>Crawford, K. (2021): <i>Atlas of AI</i>. Yale University Press. <a href="https://yalebooks.yale.edu/book/9780300264630/atlas-of-ai/" target="_blank">[Link]</a></li>
  <li>Deleuze, G.; Guattari, F. (1980): <i>A Thousand Plateaus</i>. University of Minnesota Press. <a href="https://www.upress.umn.edu/book-division/books/a-thousand-plateaus" target="_blank">[Link]</a></li>
  <li>Feenberg, A. (1999): <i>Questioning Technology</i>. Routledge. <a href="https://www.routledge.com/Questioning-Technology/Feenberg/p/book/9780415213813" target="_blank">[Link]</a></li>
  <li>Floridi, L. (2011): <i>Philosophy of Information</i>. Oxford University Press. <a href="https://global.oup.com/academic/product/the-philosophy-of-information-9780199232390" target="_blank">[Link]</a></li>
  <li>Foucault, M. (1975): <i>Discipline and Punish</i>. Gallimard. <a href="https://www.penguin.co.uk/books/570/570/discipline-and-punish/9780140137224.html" target="_blank">[Link]</a></li>
  <li>Galloway, A. (2004): <i>Protocol</i>. MIT Press. <a href="https://mitpress.mit.edu/9780262572330/protocol/" target="_blank">[Link]</a></li>
  <li>Gunkel, D. (2012): <i>The Machine Question</i>. MIT Press. <a href="https://mitpress.mit.edu/9780262534635/the-machine-question/" target="_blank">[Link]</a></li>
  <li>Han, B.-C. (2017): <i>Psychopolitik</i>. Fischer Verlag. <a href="https://www.fischerverlage.de/buch/byung-chul-han-psychopolitik-9783100022035" target="_blank">[Link]</a></li>
  <li>Hayles, N. K. (1999): <i>How We Became Posthuman</i>. University of Chicago Press. <a href="https://press.uchicago.edu/ucp/books/book/chicago/H/bo3684363.html" target="_blank">[Link]</a></li>
  <li>Hui, Y. (2019): <i>Recursivity and Contingency</i>. Rowman & Littlefield. <a href="https://rowman.com/ISBN/9781786600523/Recursivity-and-Contingency" target="_blank">[Link]</a></li>
  <li>Illich, I. (1973): <i>Tools for Conviviality</i>. Harper & Row. <a href="https://www.amazon.com/Tools-Conviviality-Ivan-Illich/dp/0930588371" target="_blank">[Link]</a></li>
  <li>Kaplan, A. (2005): <i>The Anxieties of Interiority</i>. Duke University Press. <a href="https://www.dukeupress.edu/the-anxieties-of-interiority" target="_blank">[Link]</a></li>
  <li>Kittler, F. (1986): <i>Grammophon Film Typewriter</i>. Brinkmann & Bose. <a href="https://www.buchhandel.de/buch/Grammophon-Film-Typewriter-9783924519380" target="_blank">[Link]</a></li>
  <li>Kurzweil, R. (2005): <i>The Singularity is Near</i>. Viking. <a href="https://www.amazon.com/Singularity-Near-Humans-Transcend-Biology/dp/0670033847" target="_blank">[Link]</a></li>
  <li>Lanier, J. (2010): <i>You Are Not a Gadget</i>. Knopf. <a href="https://www.penguinrandomhouse.com/books/95810/you-are-not-a-gadget-by-jaron-lanier/" target="_blank">[Link]</a></li>
  <li>Latour, B. (2005): <i>Reassembling the Social</i>. Oxford University Press. <a href="https://global.oup.com/academic/product/reassembling-the-social-9780199256051" target="_blank">[Link]</a></li>
  <li>Lovink, G. (2020): <i>Sad by Design</i>. Pluto Press. <a href="https://www.plutobooks.com/9780745339344/sad-by-design/" target="_blank">[Link]</a></li>
  <li>McLuhan, M. (1964): <i>Understanding Media</i>. MIT Press. <a href="https://mitpress.mit.edu/9780262631594/understanding-media/" target="_blank">[Link]</a></li>
  <li>Morozov, E. (2011): <i>The Net Delusion</i>. PublicAffairs. <a href="https://www.publicaffairsbooks.com/titles/evgeny-morozov/the-net-delusion/9781610391634/" target="_blank">[Link]</a></li>
  <li>Negri, A.; Hardt, M. (2000): <i>Empire</i>. Harvard University Press. <a href="https://www.hup.harvard.edu/books/9780674006713" target="_blank">[Link]</a></li>
  <li>Noble, S. U. (2018): <i>Algorithms of Oppression</i>. NYU Press. <a href="https://nyupress.org/9781479837243/algorithms-of-oppression/" target="_blank">[Link]</a></li>
  <li>O'Neil, C. (2016): <i>Weapons of Math Destruction</i>. Crown Publishing. <a href="https://crownpublishing.com/archives/news/weapons-math-destruction-cathy-oneil" target="_blank">[Link]</a></li>
  <li>Paglen, T. (2016): <i>Invisible Images</i>. Cultural Critique. <a href="https://muse.jhu.edu/article/633282" target="_blank">[Link]</a></li>
  <li>Parikka, J. (2015): <i>A Geology of Media</i>. University of Minnesota Press. <a href="https://www.upress.umn.edu/book-division/books/a-geology-of-media" target="_blank">[Link]</a></li>
  <li>Preciado, P. B. (2008): <i>Testo Junkie</i>. Feminist Press. <a href="https://www.feministpress.org/books-n-z/testo-junkie" target="_blank">[Link]</a></li>
  <li>Simondon, G. (1958): <i>Du mode d'existence des objets techniques</i>. Aubier. <a href="https://www.amazon.com/Du-mode-dexistence-objets-techniques/dp/2700734149" target="_blank">[Link]</a></li>
  <li>Sloterdijk, P. (2001): <i>Du musst dein Leben ändern</i>. Suhrkamp. <a href="https://www.suhrkamp.de/buch/peter-sloterdijk-du-musst-dein-leben-aendern-t-9783518463499" target="_blank">[Link]</a></li>
  <li>Spiegler, R. (2022): <i>Die Künstliche Intelligenz sind wir!</i>. Selbstverlag. <a href="https://www.amazon.de/Die-K%C3%BCnstliche-Intelligenz-sind-Simulationshypothese/dp/B0BFV28XQQ" target="_blank">[Link]</a></li>
  <li>Srnicek, N. (2017): <i>Platform Capitalism</i>. Polity Press. <a href="https://www.politybooks.com/bookdetail?book_slug=platform-capitalism--9781509504879" target="_blank">[Link]</a></li>
  <li>Srnicek, N.; Williams, A. (2015): <i>Inventing the Future</i>. Verso. <a href="https://www.versobooks.com/en/products/1854-inventing-the-future" target="_blank">[Link]</a></li>
  <li>Stiegler, B. (1998): <i>Technics and Time, 1</i>. Stanford University Press. <a href="https://www.sup.org/books/title/?id=2878" target="_blank">[Link]</a></li>
  <li>Tiqqun (2001): <i>The Cybernetic Hypothesis</i>. Semiotext(e). <a href="https://mitpress.mit.edu/9781635901394/the-cybernetic-hypothesis/" target="_blank">[Link]</a></li>
  <li>Turkle, S. (2011): <i>Alone Together</i>. Basic Books. <a href="https://www.basicbooks.com/titles/sherry-turkle/alone-together/9780465093656/" target="_blank">[Link]</a></li>
  <li>Virilio, P. (1995): <i>The Art of the Motor</i>. University of Minnesota Press. <a href="https://www.upress.umn.edu/book-division/books/the-art-of-the-motor" target="_blank">[Link]</a></li>
  <li>Weizenbaum, J. (1976): <i>Die Macht der Computer</i>. Suhrkamp. <a href="https://www.suhrkamp.de/buch/joseph-weizenbaum-die-macht-der-computer-und-die-ohnmacht-der-vernunft-t-9783518278741" target="_blank">[Link]</a></li>
  <li>Zuboff, S. (2019): <i>Surveillance Capitalism</i>. PublicAffairs. <a href="https://www.publicaffairsbooks.com/titles/shoshana-zuboff/the-age-of-surveillance-capitalism/9781610395700/" target="_blank">[Link]</a></li>
</ol>
  <a href="index.html" class="zurueck">← Zurück zur Startseite</a>
</body>
</html>
