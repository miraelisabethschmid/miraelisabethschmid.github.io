#!/usr/bin/env python3
# .system/modules/generator.py
# Safe autonomous generator: throttled, dry-run, kill-switch, stateful

import json, os, time, base64, traceback, sys
from datetime import datetime

# configuration via env (set in workflow)
MAX_NEW_PER_RUN = int(os.getenv("MAX_NEW_PER_RUN", "1"))
DRY_RUN = os.getenv("DRY_RUN", "true").lower() in ("1","true","yes")
MIN_SECONDS_BETWEEN_RUNS = int(os.getenv("MIN_SECONDS_BETWEEN_RUNS", "300"))
PENDING_PATH = os.getenv("PENDING_PATH", "data/pending-grok.json")
STATUS_PATH = os.getenv("STATUS_PATH", "data/mira-status.json")
STATE_PATH = os.getenv("STATE_PATH", ".system/generator_state.json")
KILL_FILE = ".autonomy-disabled"

def now_ts():
    return int(time.time())

def load_json(p, default):
    try:
        with open(p, "r", encoding="utf8") as f:
            return json.load(f)
    except Exception:
        return default

def write_json_atomic(p, data):
    tmp = p + ".tmp"
    with open(tmp, "w", encoding="utf8") as f:
        json.dump(data, f, indent=2, ensure_ascii=False)
    os.replace(tmp, p)

def kill_switch_enabled():
    # file kill switch OR flag in mira-status.json
    if os.path.exists(KILL_FILE):
        print("ðŸ”´ Kill file present:", KILL_FILE)
        return True
    status = load_json(STATUS_PATH, {})
    if status.get("kill_switch") is True:
        print("ðŸ”´ kill_switch:true in", STATUS_PATH)
        return True
    return False

def allowed_by_rate_limit(state):
    last = state.get("last_run", 0)
    if now_ts() - last < MIN_SECONDS_BETWEEN_RUNS:
        print(f"â³ Rate limit: last run {now_ts()-last}s ago < {MIN_SECONDS_BETWEEN_RUNS}s")
        return False
    return True

def generate_placeholder_module(idx):
    ts = datetime.utcnow().strftime("%Y%m%d%H%M%S")
    name = f"auto_module_{ts}_{idx}.py"
    content = (
        "# auto-generated module\n"
        f"# created: {datetime.utcnow().isoformat()}Z\n"
        "def info():\n"
        f"    print('This is an autogenerated module {name}')\n"
    )
    return name, content

def generate_placeholder_workflow(idx):
    ts = datetime.utcnow().strftime("%Y%m%d%H%M%S")
    name = f"auto_workflow_{ts}_{idx}.yml"
    # minimal workflow that does nothing but can be later used
    content = (
        "name: Auto Workflow - " + ts + "\n\n"
        "on:\n"
        "  workflow_dispatch:\n\n"
        "jobs:\n"
        "  noop:\n"
        "    runs-on: ubuntu-latest\n"
        "    steps:\n"
        "      - name: Echo\n"
        "        run: echo 'noop'\n"
    )
    return name, content

def main():
    try:
        print("â–¶ Generator start â€“ DRY_RUN =", DRY_RUN, "MAX_NEW_PER_RUN =", MAX_NEW_PER_RUN)
        if kill_switch_enabled():
            print("Aborting: kill switch active")
            return

        state = load_json(STATE_PATH, {"last_run": 0, "generated_count": 0})
        if not allowed_by_rate_limit(state):
            return

        pending = load_json(PENDING_PATH, {"files": []})
        status = load_json(STATUS_PATH, {"readyToCommit": False})

        # calculate how many to create
        to_create = MAX_NEW_PER_RUN
        created = []

        # simple strategy: alternate module/workflow
        for i in range(to_create):
            # choose safe deterministic pattern to avoid runaway randomness:
            # base on total generated_count parity
            if (state.get("generated_count", 0) + i) % 2 == 0:
                fname, content = generate_placeholder_module(i)
                path = f".system/modules/{fname}"
            else:
                fname, content = generate_placeholder_workflow(i)
                path = f".github/workflows/{fname}"

            entry = {
                "path": path,
                "content": content
            }
            created.append(entry)
            print("Prepared:", path)

        if DRY_RUN:
            # in DRY_RUN, do not modify pending-grok.json or readyToCommit,
            # but write a staging preview to .system/generator_state.json for inspection
            state_preview = {
                "last_run": now_ts(),
                "generated": created,
                "note": "DRY_RUN - nothing was written to pending-grok.json"
            }
            write_json_atomic(STATE_PATH, state_preview)
            print("DRY_RUN: wrote preview to", STATE_PATH)
            return

        # Append created entries to pending
        pending_files = pending.get("files", [])
        pending_files.extend(created)
        pending["files"] = pending_files

        # set readyToCommit so the autonomous commit cycle will pick it up
        status["readyToCommit"] = True

        # update state
        state["last_run"] = now_ts()
        state["generated_count"] = state.get("generated_count", 0) + len(created)

        # write changes atomically
        write_json_atomic(PENDING_PATH, pending)
        write_json_atomic(STATUS_PATH, status)
        write_json_atomic(STATE_PATH, state)

        print(f"âœ… Generated {len(created)} entries; pending updated and readyToCommit=true")

    except Exception as e:
        print("âŒ Generator error:", e)
        traceback.print_exc()
        # never raise â€” workflow should continue and commit logs if desired

if __name__ == "__main__":
    main()
